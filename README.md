# Social Buzz Data Analysis

Social Buzz, a San Francisco-based company established in 2010 by former engineers from a leading social media conglomerate, has seen explosive growth, now boasting over 500 million monthly active users. Focusing on content and user reactions, they aim to take content center stage while keeping users anonymous. With 200 technical employees out of a total of 250, Social Buzz handles vast amounts of unstructured data. In preparation for an impending IPO, they're seeking Accenture's expertise to facilitate their scaling process.

My data analysis task centered on identifying Social Buzz's top 5 content categories. This involved stages like data understanding, data cleaning, data modeling, data analysis, and uncovering insights. Of the 7 data sets provided, including User, Profile, Location, Session, Content, Reaction, and Reaction Types, I will focus on Reaction, Content, and Reaction Types for the analysis. The client's request was to determine the top 5 content categories by analyzing the "Score" assigned to each reaction type in the data model.

Before working with the datasets, I used Python and SQL  to explore the data, removed missing values, adjusted data types, and eliminated irrelevant columns. Then performed data analysis on cleaned data. 

There are identified 16 unique categories, with animals being the most popular (21.4%), followed by science (20.3%), healthy eating (19.8%), technology (19.6%), and food (19%). Healthy eating's prominence among the top 5 categories could provide valuable insights because Social Buzz can collaborate more with healthy eating brands to increase engagement with audiences. 
![Alt text] (https://github.com/ByThaoNguyen/Social-Buzz-Data-Analysis/blob/master/Popularity%20Percentage.png?raw=true)

Replicating the same analysis in real-time will be needed to validate the findings and potentially adapt the strategy accordingly.

## FYI
This is a virtual job simulation by Forage in collaboration with Accenture. Instead of using Excel as the guidance, I used Python and SQL as the primary tools. Please see the Jupiter notebook for the details of the code.
